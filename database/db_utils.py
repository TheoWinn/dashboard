import psycopg2
import csv
import pandas as pd
import unicodedata
import hashlib
import sys
import ast

def create_db(db_url):

    create_private_schema = """
    CREATE SCHEMA IF NOT EXISTS private;
    """

    create_speakers_table = """
    CREATE TABLE IF NOT EXISTS private.speakers (
        speaker_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        speaker_name TEXT,
        speaker_party TEXT,
        UNIQUE (speaker_name, speaker_party)
    );"""

    create_files_table = """
    CREATE TABLE IF NOT EXISTS private.files (
        file_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        file_name TEXT NOT NULL,
        file_url TEXT,
        file_date DATE,
        file_year INTEGER,
        source TEXT NOT NULL,
        talkshow_name TEXT,
        CONSTRAINT cource_check CHECK (source IN ('bundestag', 'talkshow')),
        UNIQUE (file_name)
    );"""

    create_topics_table = """
    CREATE TABLE IF NOT EXISTS private.topics (
        topic_id INTEGER NOT NULL PRIMARY KEY,
        topic_keywords TEXT,
        topic_label TEXT,
        topic_repdoc TEXT[],
        topic_duration INTERVAL NOT NULL DEFAULT INTERVAL '0',
        topic_duration_bt INTERVAL NOT NULL DEFAULT INTERVAL '0',
        topic_duration_ts INTERVAL NOT NULL DEFAULT INTERVAL '0',
        UNIQUE (topic_keywords, topic_label)
    );"""

    create_table_speeches = """
    CREATE TABLE IF NOT EXISTS private.speeches (
        speech_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        speech_key TEXT NOT NULL,
        speech_text TEXT,
        speech_duration INTERVAL,
        file BIGINT,
        speaker BIGINT,
        topic INTEGER,
        CONSTRAINT fk_file FOREIGN KEY (file) REFERENCES private.files(file_id),
        CONSTRAINT fk_speaker FOREIGN KEY (speaker) REFERENCES private.speakers(speaker_id),
        CONSTRAINT fk_topic FOREIGN KEY (topic) REFERENCES private.topics(topic_id),
        UNIQUE (speech_key)
    );"""

    default_speaker = """
    INSERT INTO private.speakers (speaker_name, speaker_party)
    VALUES ('Unknown', 'Unknown')
    ON CONFLICT (speaker_name, speaker_party) DO NOTHING;
    """

    function_trigger_insert = """
    CREATE OR REPLACE FUNCTION private.trgfn_topic_duration_insert()
    RETURNS TRIGGER
    LANGUAGE plpgsql
    AS $$
    BEGIN
        UPDATE private.topics
        SET topic_duration = topic_duration + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic;
        
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'bundestag'
            );
        
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'talkshow'
            );
        
        RETURN NEW;
    END;
    $$;"""

    function_trigger_update = """
    CREATE OR REPLACE FUNCTION private.trgfn_topic_duration_update()
    RETURNS TRIGGER
    LANGUAGE plpgsql
    AS $$
    BEGIN
        UPDATE private.topics
        SET topic_duration = topic_duration - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic;
        UPDATE private.topics
        SET topic_duration = topic_duration + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic;
        
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'bundestag'
            );
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'bundestag'
            );
        
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'talkshow'
            );
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'talkshow'
            );
        
        RETURN NEW;
    END;
    $$;"""

    function_trigger_delete = """
    CREATE OR REPLACE FUNCTION private.trgfn_topic_duration_delete()
    RETURNS TRIGGER
    LANGUAGE plpgsql
    AS $$
    BEGIN
        UPDATE private.topics
        SET topic_duration = topic_duration - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic;
        
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'bundestag'
            );
        
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'talkshow'
            );
        
        RETURN NEW;
    END;
    $$;"""

    trigger_insert = """
    CREATE TRIGGER trg_topic_duration_insert
    AFTER INSERT ON private.speeches
    FOR EACH ROW
    EXECUTE FUNCTION private.trgfn_topic_duration_insert();"""

    trigger_update = """
    CREATE TRIGGER trg_topic_duration_update
    AFTER UPDATE ON private.speeches
    FOR EACH ROW
    EXECUTE FUNCTION private.trgfn_topic_duration_update();"""

    trigger_delete = """
    CREATE TRIGGER trg_topic_duration_delete
    AFTER DELETE ON private.speeches
    FOR EACH ROW
    EXECUTE FUNCTION private.trgfn_topic_duration_delete();"""


    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute(create_private_schema)
            cur.execute(create_speakers_table)
            cur.execute(create_files_table)
            cur.execute(create_topics_table)
            cur.execute(create_table_speeches)
            cur.execute(default_speaker)
            cur.execute(function_trigger_insert)
            cur.execute(function_trigger_update)
            cur.execute(function_trigger_delete)
            cur.execute(trigger_insert)
            cur.execute(trigger_update)
            cur.execute(trigger_delete)
        conn.commit()

    print("Database and tables created successfully.")

def views_db(db_url):
    
    create_schemas = """
    CREATE SCHEMA IF NOT EXISTS dashboard;
    CREATE SCHEMA IF NOT EXISTS dashboard_internal;
    """

    create_roles = """
    DO $$
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'dashboard_owner') THEN
            CREATE ROLE dashboard_owner NOINHERIT;
        END IF;
        IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'dashboard_reader') THEN
            CREATE ROLE dashboard_reader NOINHERIT;
        END IF;
    END;
    $$;
    """

    ownership_schemas = """
    ALTER SCHEMA dashboard OWNER TO dashboard_owner;
    ALTER SCHEMA dashboard_internal OWNER TO dashboard_owner;
    """

    lockdown_schemas = """
    REVOKE ALL ON SCHEMA dashboard_internal FROM PUBLIC, anon, authenticated;
    REVOKE ALL ON SCHEMA private FROM PUBLIC, anon, authenticated;
    REVOKE ALL ON SCHEMA dashboard FROM PUBLIC, anon, authenticated;
    """

    grant_select_private = """
    GRANT SELECT ON private.speeches TO dashboard_owner;
    GRANT SELECT ON private.topics TO dashboard_owner;
    GRANT SELECT ON private.files TO dashboard_owner;
    GRANT USAGE ON SCHEMA private TO dashboard_owner
    """

    # security definer function in dashboard_internal (are executed with owners privileges)
    sd_functions = """
    -- topics read function
    CREATE OR REPLACE FUNCTION dashboard_internal._fn_topics_read()
    RETURNS TABLE (
        topic_id INTEGER,
        topic_keywords TEXT,
        topic_label TEXT,
        topic_repdoc TEXT[],
        topic_duration INTERVAL,
        topic_duration_bt INTERVAL,
        topic_duration_ts INTERVAL
    )
    LANGUAGE sql
    SECURITY DEFINER SET search_path = pg_catalog, private
    STABLE
    AS $$
        SELECT * 
        FROM private.topics;
    $$;
    REVOKE ALL ON FUNCTION dashboard_internal._fn_topics_read() FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard_internal._fn_topics_read() TO dashboard_reader;

    -- files read function
    CREATE OR REPLACE FUNCTION dashboard_internal._fn_files_read()
    RETURNS TABLE (
        file_id BIGINT,
        file_url TEXT,
        file_date DATE,
        source TEXT,
        talkshow_name TEXT
    )
    LANGUAGE sql
    SECURITY DEFINER SET search_path = pg_catalog, private
    STABLE
    AS $$
        SELECT file_id, file_url, file_date, source, talkshow_name
        FROM private.files;
    $$;
    REVOKE ALL ON FUNCTION dashboard_internal._fn_files_read() FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard_internal._fn_files_read() TO dashboard_reader;

    -- speakers read function
    CREATE OR REPLACE FUNCTION dashboard_internal._fn_speakers_read()
    RETURNS TABLE (
        speaker_id BIGINT,
        speaker_name TEXT,
        speaker_party TEXT
    )
    LANGUAGE sql
    SECURITY DEFINER SET search_path = pg_catalog, private
    STABLE
    AS $$
        SELECT * 
        FROM private.speakers;
    $$;
    REVOKE ALL ON FUNCTION dashboard_internal._fn_speakers_read() FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard_internal._fn_speakers_read() TO dashboard_reader;

    -- function for windowed metrics
    CREATE OR REPLACE FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(
        p_year         int,
        p_window_weeks int
    )
    RETURNS TABLE (
        window_start date,
        window_end   date,

        topic_id integer,
        topic_label text,
        topic_keywords text,
        topic_repdoc text[],

        topic_duration interval,
        topic_duration_bt interval,
        topic_duration_ts interval,

        bt_normalized_perc numeric,
        ts_normalized_perc numeric,

        mismatch_ppoints numeric,
        mismatch_log_ratio numeric
    )
    LANGUAGE sql
    SECURITY DEFINER
    SET search_path = pg_catalog, private
    STABLE
    AS $$
    WITH params AS (
    SELECT
        make_date(p_year, 1, 1)::date         AS start_date,
        COALESCE(
            (SELECT (max(f.file_date) + 1)::date
             FROM private.files f
             WHERE f.file_date >= make_date(p_year, 1, 1)::date),
            /* fallback if no data exists at/after start_date */
            make_date(p_year + 1, 1, 1)::date
        ) AS end_date,
        (p_window_weeks || ' weeks')::interval AS step
    ),
    windows AS (
    SELECT
        gs::date AS window_start,
        LEAST((gs + p.step)::date, p.end_date) AS window_end
    FROM params p
    CROSS JOIN generate_series(p.start_date, p.end_date - p.step, p.step) AS gs
    ),
    speech_rows AS (
    SELECT
        w.window_start,
        w.window_end,
        s.topic AS topic_id,
        f.source,
        s.speech_duration
    FROM windows w
    JOIN private.files f
        ON f.file_date >= w.window_start
    AND f.file_date <  w.window_end
    JOIN private.speeches s
        ON s.file = f.file_id
    WHERE s.topic IS NOT NULL
    ),
    agg AS (
    SELECT
        window_start,
        window_end,
        topic_id,
        SUM(speech_duration) AS topic_duration,
        SUM(speech_duration) FILTER (WHERE source = 'bundestag') AS topic_duration_bt,
        SUM(speech_duration) FILTER (WHERE source = 'talkshow')  AS topic_duration_ts
    FROM speech_rows
    GROUP BY 1,2,3
    ),
    base AS (
    SELECT
        a.window_start,
        a.window_end,
        t.topic_id,
        t.topic_label,
        t.topic_keywords,
        t.topic_repdoc,
        a.topic_duration,
        a.topic_duration_bt,
        a.topic_duration_ts,
        EXTRACT(EPOCH FROM a.topic_duration_bt)::numeric AS bt_seconds,
        EXTRACT(EPOCH FROM a.topic_duration_ts)::numeric AS ts_seconds
    FROM agg a
    JOIN private.topics t ON t.topic_id = a.topic_id
    ),
    norm AS (
    SELECT
        *,
        bt_seconds / NULLIF(SUM(bt_seconds) OVER (PARTITION BY window_start), 0) AS bt_normalized,
        ts_seconds / NULLIF(SUM(ts_seconds) OVER (PARTITION BY window_start), 0) AS ts_normalized
    FROM base
    )
    SELECT
    window_start,
    window_end,

    topic_id,
    topic_label,
    topic_keywords,
    topic_repdoc,

    topic_duration,
    topic_duration_bt,
    topic_duration_ts,

    (bt_normalized * 100) AS bt_normalized_perc,
    (ts_normalized * 100) AS ts_normalized_perc,
    (bt_normalized - ts_normalized)*100 AS mismatch_ppoints,
    log(2, (bt_normalized+0.0000001)/(ts_normalized+0.0000001)) AS mismatch_log_ratio
    FROM norm
    ORDER BY window_start, topic_id;
    $$;

    REVOKE ALL ON FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(int,int)
    FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(int,int)
    TO dashboard_reader;

    -- public wrapper function for windowed metrics
    CREATE OR REPLACE FUNCTION dashboard.topics_metrics_all_xweek_windows(
    p_year int,
    p_window_weeks int
    )
    RETURNS TABLE (
    window_start date,
    window_end   date,

    topic_id integer,
    topic_label text,
    topic_keywords text,
    topic_repdoc text[],

    topic_duration interval,
    topic_duration_bt interval,
    topic_duration_ts interval,

    bt_normalized_perc numeric,
    ts_normalized_perc numeric,

    mismatch_ppoints numeric,
    mismatch_log_ratio numeric
    )
    LANGUAGE sql
    SECURITY DEFINER
    SET search_path = pg_catalog  
    STABLE
    AS $$
    SELECT *
    FROM dashboard_internal._fn_topics_metrics_all_xweek_windows(p_year, p_window_weeks)
    WHERE topic_id <> -1;
    $$;

    REVOKE ALL ON FUNCTION dashboard.topics_metrics_all_xweek_windows(int,int)
    FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard.topics_metrics_all_xweek_windows(int,int)
    TO dashboard_reader;
    """

    ownership_functions = """
    ALTER FUNCTION dashboard_internal._fn_topics_read() OWNER TO dashboard_owner;
    ALTER FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(int,int) OWNER TO dashboard_owner;
    ALTER FUNCTION dashboard.topics_metrics_all_xweek_windows(int,int) OWNER TO dashboard_owner;
    """

    create_views = """
    -- topics view
    CREATE OR REPLACE VIEW dashboard.topics_view AS
    WITH base AS (
    SELECT
        topic_id,
        topic_label,
        topic_keywords,
        topic_repdoc,
        topic_duration,
        topic_duration_bt,
        topic_duration_ts,

        -- convert intervals to seconds (numeric)
        EXTRACT(EPOCH FROM topic_duration_bt)::numeric AS bt_seconds,
        EXTRACT(EPOCH FROM topic_duration_ts)::numeric AS ts_seconds
    FROM dashboard_internal._fn_topics_read()
    ),
    norm AS (
    SELECT
        *,
        bt_seconds / NULLIF(SUM(bt_seconds) OVER (), 0) AS bt_normalized,
        ts_seconds / NULLIF(SUM(ts_seconds) OVER (), 0) AS ts_normalized
    FROM base
    )
    SELECT
    topic_id,
    topic_label,
    topic_keywords,
    topic_duration,
    topic_repdoc,
    topic_duration_bt,
    topic_duration_ts,
    (bt_normalized*100) AS bt_normalized_perc,
    (ts_normalized*100) AS ts_normalized_perc,
    (bt_normalized / NULLIF(bt_normalized + ts_normalized, 0))*100 AS bt_share,
    (ts_normalized / NULLIF(bt_normalized + ts_normalized, 0))*100 AS ts_share,
    (bt_normalized - ts_normalized)*100 AS mismatch_ppoints,
    log(2, (bt_normalized+0.0000001)/(ts_normalized+0.0000001)) AS mismatch_log_ratio
    FROM norm
    WHERE topic_id <> -1;

    -- 4-week windowed metrics view
    CREATE OR REPLACE VIEW dashboard.topics_view_4w AS
    SELECT *
    FROM dashboard_internal._fn_topics_metrics_all_xweek_windows(2025, 4)
    WHERE topic_id <> -1;

    -- files view
    CREATE OR REPLACE VIEW dashboard.files_view AS
    SELECT *
    FROM dashboard_internal._fn_files_read();

    -- speakers view
    CREATE OR REPLACE VIEW dashboard.speakers_view AS
    SELECT *
    FROM dashboard_internal._fn_speakers_read();
    """

    ownership_views = """
    ALTER VIEW dashboard.topics_view OWNER TO dashboard_owner;
    ALTER VIEW dashboard.topics_view_4w OWNER TO dashboard_owner;
    ALTER VIEW dashboard.files_view OWNER TO dashboard_owner;
    ALTER VIEW dashboard.speakers_view OWNER TO dashboard_owner;
    """

    minimal_rights = """
    GRANT USAGE ON SCHEMA dashboard TO dashboard_reader;
    REVOKE ALL ON dashboard.topics_view FROM PUBLIC, anon, authenticated;
    GRANT SELECT ON dashboard.topics_view TO dashboard_reader;
    REVOKE ALL ON dashboard.topics_view_4w FROM PUBLIC, anon, authenticated;
    GRANT SELECT ON dashboard.topics_view_4w TO dashboard_reader;
    REVOKE ALL ON dashboard.files_view FROM PUBLIC, anon, authenticated;
    GRANT SELECT ON dashboard.files_view TO dashboard_reader;
    REVOKE ALL ON dashboard.speakers_view FROM PUBLIC, anon, authenticated;
    GRANT SELECT ON dashboard.speakers_view TO dashboard_reader;
    """

    grant_anon_role = """
    GRANT dashboard_reader TO anon;"""

    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute(create_schemas)
            cur.execute(create_roles)
            cur.execute(ownership_schemas)
            cur.execute(lockdown_schemas)
            cur.execute(grant_select_private)
            cur.execute(sd_functions)
            cur.execute(ownership_functions)
            cur.execute(create_views)
            cur.execute(ownership_views)
            cur.execute(minimal_rights)
            cur.execute(grant_anon_role)
            
        conn.commit()

def comment_db(db_url):
    views = """
    COMMENT ON VIEW dashboard.topics_view IS 
    'This view contains general information on all the topics identified in Bundestag and Talkshow speeches.';
    COMMENT ON VIEW dashboard.topics_view_4w IS 
    'This view contains the same measurements as topics_view, but for a 4-week window. That means, one row in this view represents one specific topic that was talked about in a specific 4-week window.';
    COMMENT ON VIEW dashboard.files_view IS 
    'This view contains general information about the protocols from the Bundestag and Talkshows.';
    COMMENT ON VIEW dashboard.speakers_view IS
    'This view contains all speakers identified in Bundestag protocols.';
    """

    functions = """
    COMMENT ON FUNCTION dashboard.topics_metrics_all_xweek_windows (int, int) IS 
    'This function returns the topic measurements for a user defined timewindow and year.
    
    Paraneters:
    - p_year: Time windows start at this calender year and go up to the latest date
    - p_window_weeks: window size in weeks (e.g. 4)
    
    The output of the function is a table with the same columns as in topics_view_4w';
    """

    columns = """
    -- topics_view
    COMMENT ON COLUMN dashboard.topics_view.topic_id IS
    'Unique topic identifier';
    COMMENT ON COLUMN dashboard.topics_view.topic_label IS
    'Labels of topics';
    COMMENT ON COLUMN dashboard.topics_view.topic_keywords IS
    'Descriptive keywords of topic';
    COMMENT ON COLUMN dashboard.topics_view.topic_repdoc IS
    'Representative Speeches';
    COMMENT ON COLUMN dashboard.topics_view.topic_duration IS
    'Overall observed speech time spent on topic without differentiating between Bundestag and Talkshows';
    COMMENT ON COLUMN dashboard.topics_view.topic_duration_bt IS
    'Observed speech time spent on topic in Bundestag';
    COMMENT ON COLUMN dashboard.topics_view.topic_duration_ts IS
    'Observed speech time spent on topic in Talkshows';
    COMMENT ON COLUMN dashboard.topics_view.bt_normalized_perc IS
    'Normalized topic speech time in Bundestag in percentages; constructed by dividing the observed time spent on specific topic in Bundestag by the total observed speech time in Bundestag.';
    COMMENT ON COLUMN dashboard.topics_view.ts_normalized_perc IS
    'Normalized topic speech time in Talkshows in percentages; constructed by dividing the observed time spent on specific topic in Talkshows by the total observed speech time in Talkshows.';
    COMMENT ON COLUMN dashboard.topics_view.bt_share IS
    'Normalized share of salience in Bundestag in percentages; constructed by dividing the normalized topic speech time of Bundestag with the total normalized topic speech time.';
    COMMENT ON COLUMN dashboard.topics_view.ts_share IS
    'Normalized share of salience in Talkshows in percentages; constructed by dividing the normalized topic speech time of Talkshows with the total normalized topic speech time.';
    COMMENT ON COLUMN dashboard.topics_view.mismatch_ppoints IS
    'Difference of normalized topic speech time in Bundestag and Talkshows in percentage points (ranges from -100 to 100); positive means higher salience of topic in Bundestag, negative means higher salience in Talkshows, 0 indicates equal salience.';
    COMMENT ON COLUMN dashboard.topics_view.mismatch_log_ratio IS
    'Log (base 2) of ratio of normalized topic speech times in Bundestag and Talkshows; generally, positive means higher salience of topic in Bundestag (max: 23.25), negative means higher salience in Talkshows (min: -23.25), 0 indicates equal salience.';
    
    -- topics_view_4w
    COMMENT ON COLUMN dashboard.topics_view_4w.window_start IS
    'Start date of window (inclusive)';
    COMMENT ON COLUMN dashboard.topics_view_4w.window_end IS
    'End date of window (exclusive)';
    COMMENT ON COLUMN dashboard.topics_view_4w.topic_id IS
    'Unique topic identifier';
    COMMENT ON COLUMN dashboard.topics_view_4w.topic_label IS
    'Labels of topics';
    COMMENT ON COLUMN dashboard.topics_view_4w.topic_keywords IS
    'Descriptive keywords of topic';
    COMMENT ON COLUMN dashboard.topics_view_4w.topic_repdoc IS
    'Representative Speeches';
    COMMENT ON COLUMN dashboard.topics_view_4w.topic_duration IS
    'Overall observed speech time spent on topic without differentiating between Bundestag and Talkshows';
    COMMENT ON COLUMN dashboard.topics_view_4w.topic_duration_bt IS
    'Observed speech time spent on topic in Bundestag';
    COMMENT ON COLUMN dashboard.topics_view_4w.topic_duration_ts IS
    'Observed speech time spent on topic in Talkshows';
    COMMENT ON COLUMN dashboard.topics_view_4w.bt_normalized_perc IS
    'Normalized topic speech time in Bundestag in percentages; constructed by dividing the observed time spent on specific topic in Bundestag by the total observed speech time in Bundestag.';
    COMMENT ON COLUMN dashboard.topics_view_4w.ts_normalized_perc IS
    'Normalized topic speech time in Talkshows in percentages; constructed by dividing the observed time spent on specific topic in Talkshows by the total observed speech time in Talkshows.';
    COMMENT ON COLUMN dashboard.topics_view_4w.mismatch_ppoints IS
    'Difference of normalized topic speech time in Bundestag and Talkshows in percentage points (ranges from -100 to 100); positive means higher salience of topic in Bundestag, negative means higher salience in Talkshows, 0 indicates equal salience.';
    COMMENT ON COLUMN dashboard.topics_view_4w.mismatch_log_ratio IS
    'Log (base 2) of ratio of normalized topic speech times in Bundestag and Talkshows; generally, positive means higher salience of topic in Bundestag (max: 23.25), negative means higher salience in Talkshows (min: -23.25), 0 indicates equal salience.';

    COMMENT ON COLUMN dashboard.files_view.file_id IS
    'Unique file identifier';
    COMMENT ON COLUMN dashboard.files_view.file_url IS
    'Link to either Bundestag protocol in pdf form or Talkshow video on youtube';
    COMMENT ON COLUMN dashboard.files_view.file_date IS
    'Date of Bundestag session or Talkshow';
    COMMENT ON COLUMN dashboard.files_view.source IS
    'Indicator whether file comes from Bundestag or Talkshows (can be either "bundestag" or "talkshow")';
    COMMENT ON COLUMN dashboard.files_view.talkshow_name IS
    'Name of Talkshow (if source is "bundestag" than this columns is also "bundestag")';

    COMMENT ON COLUMN dashboard.speakers_view.speaker_id IS
    'Unique speaker identifier';
    COMMENT ON COLUMN dashboard.speakers_view.speaker_name IS
    'Name of speaker';
    COMMENT ON COLUMN dashboard.speakers_view.speaker_party IS
    'Party or role of speaker';
    """

    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute(views)
            cur.execute(functions)
            cur.execute(columns)
            
        conn.commit()


def fill_db(db_url, input_path, label_path, youtube):

    def norm_text(x):
        if x is None or pd.isna(x):
            return "Unknown"
        x = unicodedata.normalize("NFKC", str(x))
        x = x.replace("\u00A0", " ").strip()
        return x if x else "Unknown"

    def make_speech_key(speech_text, seconds, file_id, speaker_id, topic_id):
        raw = f"{speech_text}|{seconds}|{file_id}|{speaker_id}|{topic_id}"
        return hashlib.sha256(raw.encode("utf-8")).hexdigest()

    upsert_speaker = """
    INSERT INTO private.speakers (speaker_name, speaker_party)
    VALUES (%s, %s)
    ON CONFLICT (speaker_name, speaker_party)
    DO UPDATE SET 
        speaker_name = EXCLUDED.speaker_name
    RETURNING speaker_id;"""

    upsert_file = """
    INSERT INTO private.files (file_name, file_url, file_date, file_year, source, talkshow_name)
    VALUES (%s, %s, %s, %s, %s, %s)
    ON CONFLICT (file_name)
    DO UPDATE SET 
        file_name = EXCLUDED.file_name
    RETURNING file_id;"""

    upsert_topic = """
    INSERT INTO private.topics (topic_id, topic_keywords, topic_label, topic_repdoc)
    VALUES (%s, %s, %s, %s)
    ON CONFLICT (topic_id)
    DO NOTHING;"""

    upsert_speech = """
    INSERT INTO private.speeches (speech_key, speech_text, speech_duration, file, speaker, topic)
    VALUES (%s, %s, make_interval(secs => %s), %s, %s, %s)
    ON CONFLICT (speech_key)
    DO NOTHING;"""

    if not youtube:
        bt_meta = pd.read_csv("../bundestag/data/raw/metadata.csv")
        bt_meta["filename"] = bt_meta.apply(lambda r: f"{r["date_formatted"]}_matched.csv", axis=1)
    else:
        cols = ["url", "title", "channel", "date"]
        bt_meta = pd.read_csv("../youtube/data/raw/bundestag_audio/metadata.csv", header=None, names=cols)
        bt_meta["filename"] = bt_meta.apply(lambda r: f"{r["date"]}_{r["title"]}_clustered.csv", axis=1)

    cols = ["url", "title", "channel", "date", "talkshow_name"]
    ts_meta = pd.read_csv("../youtube/data/raw/talkshow_audio/metadata.csv", header=None, names=cols)
    ts_meta["filename"] = ts_meta.apply(lambda r: f"{r["date"]}_{r["title"]}_clustered.csv", axis=1)

    max_int = sys.maxsize
    max_int = 922337203 # for local, cluster may be higher?
    while True:
        try:
            csv.field_size_limit(max_int)
            break
        except OverflowError:
            print(f"have to reduce {max_int}")
            max_int = int(max_int / 10)

    speaker_cache = {}
    file_cache = {}

    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:

            # insert topics
            if label_path != "none":
                with open(label_path, encoding="utf-8") as la:
                    reader = csv.DictReader(la)
                    for row in reader:
                        topic_id = row["topic"]
                        topic_keywords = row["Representation"]
                        topic_label = row["Gemini_Label"]
                        topic_repdoc = ast.literal_eval(row["Representative_Docs"])
                        cur.execute(upsert_topic, (topic_id, topic_keywords, topic_label, topic_repdoc))
                conn.commit()
                print("Successfully inserted info on topics.")
            else:
                print("No new topics given, so none were inserted.")

            # insert rest
            if input_path != "none":
                with open(input_path, encoding="utf-8") as tr:
                    reader = csv.DictReader(tr)
                    for i, row in enumerate(reader, start=1):
                        # getting data
                        if not youtube:
                            speaker_name = norm_text(row["protokoll_name"])
                            speaker_party = norm_text(row["protokoll_party"])
                        file_name = norm_text(row["filename"])
                        file_date = norm_text(row["date"])
                        file_year = int(file_date[:4])
                        source = row["source"]
                        if not youtube and source == "bundestag":
                            seconds = float(row["transcript_end"]) - float(row["transcript_start"])
                        elif youtube or (not youtube and source == "talkshow"):
                            seconds = float(row["end"]) - float(row["start"])
                        else:
                            print(f"Unknown source: {source}")
                            continue
                        topic_id = int(row["topic"])
                        speech_text = norm_text(row["text"]) 
                        talkshow_name = "bundestag" 
                        if "matched" in file_name:
                            url = bt_meta.loc[bt_meta["filename"] == file_name, "fundstelle.pdf_url"] 
                        elif "clustered" in file_name:
                            if source == "bundestag":
                                url = bt_meta.loc[bt_meta["filename"] == file_name, "url"]  
                            elif source == "talkshow":
                                url = ts_meta.loc[ts_meta["filename"] == file_name, "url"]
                                ts_name = ts_meta.loc[ts_meta["filename"] == file_name, "talkshow_name"] 
                                if not ts_name.empty:
                                    talkshow_name = ts_name.values[0] 
                                else:
                                    talkshow_name = "not found"
                            else:
                                print(f"Unknown source: {source}")
                                continue
                        else:
                            print(f"Unknown file used: {file_name}")
                            continue
                        file_raw_url = "Unknown"
                        if not url.empty:
                            file_raw_url = url.values[0]
                        else:
                            print(f"Unknown URL for file: {file_name}, still inserted")
                        
                        # upserting data
                        # speaker
                        if not youtube:
                            skey = (speaker_name, speaker_party)
                            speaker_id = speaker_cache.get(skey)
                            if speaker_id is None:
                                cur.execute(upsert_speaker, (speaker_name, speaker_party))
                                speaker_id = cur.fetchone()[0]
                                speaker_cache[skey] = speaker_id
                        # file
                        file_id = file_cache.get(file_name)
                        if file_id is None:
                            cur.execute(upsert_file, (file_name, file_raw_url, file_date, file_year, source, talkshow_name))
                            file_id = cur.fetchone()[0]
                            file_cache[file_name] = file_id
                        # speech
                        if youtube:
                            speaker_id = 1
                        speech_key = make_speech_key(speech_text, seconds, file_id, speaker_id, topic_id)
                        cur.execute(upsert_speech, (speech_key, speech_text, seconds, file_id, speaker_id, topic_id))
                
                        # committing
                        if i % 5000 == 0:
                            conn.commit()
                            print(f"Inserted/updated {i} rows...")
                conn.commit()
                print("Successfully inserted speeches.")
            else:
                print("No new speeches given, so none were inserted.")

    print("Database population completed.")

def rebuild_db(db_url, input_path, label_path, youtube):

    # delete everything
    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute("drop schema if exists private cascade;")
            cur.execute("drop schema if exists dashboard_internal cascade;")
            cur.execute("drop schema if exists dashboard cascade;")
        conn.commit()

    # rebuild private schema
    create_db(db_url)

    # rebuild views for dashboard
    views_db(db_url)

    # comment for api
    comment_db(db_url)

    # fill with data
    fill_db(db_url, input_path, label_path, youtube)

def rebuild_views(db_url):

    # delete everything
    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute("drop schema if exists dashboard_internal cascade;")
            cur.execute("drop schema if exists dashboard cascade;")
        conn.commit()

    # rebuild views for dashboard
    views_db(db_url)

    # comment for api
    comment_db(db_url)