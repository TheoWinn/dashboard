import psycopg2
import csv
import pandas as pd
import unicodedata
import hashlib

def create_db(db_url):

    create_private_schema = """
    CREATE SCHEMA IF NOT EXISTS private;
    """

    create_speakers_table = """
    CREATE TABLE IF NOT EXISTS private.speakers (
        speaker_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        speaker_name TEXT,
        speaker_party TEXT,
        UNIQUE (speaker_name, speaker_party)
    );"""

    create_files_table = """
    CREATE TABLE IF NOT EXISTS private.files (
        file_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        file_name TEXT NOT NULL,
        file_date DATE,
        file_year INTEGER,
        source TEXT NOT NULL,
        CONSTRAINT cource_check CHECK (source IN ('bundestag', 'talkshow')),
        UNIQUE (file_name)
    );"""

    create_topics_table = """
    CREATE TABLE IF NOT EXISTS private.topics (
        topic_id INTEGER NOT NULL PRIMARY KEY,
        topic_keywords TEXT,
        topic_label TEXT,
        topic_duration INTERVAL NOT NULL DEFAULT INTERVAL '0',
        topic_duration_bt INTERVAL NOT NULL DEFAULT INTERVAL '0',
        topic_duration_ts INTERVAL NOT NULL DEFAULT INTERVAL '0',
        UNIQUE (topic_keywords, topic_label)
    );"""

    create_table_speeches = """
    CREATE TABLE IF NOT EXISTS private.speeches (
        speech_id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        speech_key TEXT NOT NULL,
        speech_text TEXT,
        speech_duration INTERVAL,
        file BIGINT,
        speaker BIGINT,
        topic INTEGER,
        CONSTRAINT fk_file FOREIGN KEY (file) REFERENCES private.files(file_id),
        CONSTRAINT fk_speaker FOREIGN KEY (speaker) REFERENCES private.speakers(speaker_id),
        CONSTRAINT fk_topic FOREIGN KEY (topic) REFERENCES private.topics(topic_id),
        UNIQUE (speech_key)
    );"""

    default_speaker = """
    INSERT INTO private.speakers (speaker_name, speaker_party)
    VALUES ('Unknown', 'Unknown')
    ON CONFLICT (speaker_name, speaker_party) DO NOTHING;
    """

    function_trigger_insert = """
    CREATE OR REPLACE FUNCTION private.trgfn_topic_duration_insert()
    RETURNS TRIGGER
    LANGUAGE plpgsql
    AS $$
    BEGIN
        UPDATE private.topics
        SET topic_duration = topic_duration + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic;
        
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'bundestag'
            );
        
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'talkshow'
            );
        
        RETURN NEW;
    END;
    $$;"""

    function_trigger_update = """
    CREATE OR REPLACE FUNCTION private.trgfn_topic_duration_update()
    RETURNS TRIGGER
    LANGUAGE plpgsql
    AS $$
    BEGIN
        UPDATE private.topics
        SET topic_duration = topic_duration - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic;
        UPDATE private.topics
        SET topic_duration = topic_duration + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic;
        
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'bundestag'
            );
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'bundestag'
            );
        
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'talkshow'
            );
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts + coalesce(NEW.speech_duration, INTERVAL '0')
        WHERE topic_id = NEW.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = NEW.file AND f.source = 'talkshow'
            );
        
        RETURN NEW;
    END;
    $$;"""

    function_trigger_delete = """
    CREATE OR REPLACE FUNCTION private.trgfn_topic_duration_delete()
    RETURNS TRIGGER
    LANGUAGE plpgsql
    AS $$
    BEGIN
        UPDATE private.topics
        SET topic_duration = topic_duration - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic;
        
        UPDATE private.topics
        SET topic_duration_bt = topic_duration_bt - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'bundestag'
            );
        
        UPDATE private.topics
        SET topic_duration_ts = topic_duration_ts - coalesce(OLD.speech_duration, INTERVAL '0')
        WHERE topic_id = OLD.topic
            AND EXISTS (
                SELECT 1
                FROM private.files f
                WHERE f.file_id = OLD.file AND f.source = 'talkshow'
            );
        
        RETURN NEW;
    END;
    $$;"""

    trigger_insert_drop = """
    DROP TRIGGER IF EXISTS trg_topic_duratoin_insert ON private.speeches;"""

    trigger_insert = """
    CREATE TRIGGER trg_topic_duration_insert
    AFTER INSERT ON private.speeches
    FOR EACH ROW
    EXECUTE FUNCTION private.trgfn_topic_duration_insert();"""

    trigger_update_drop = """
    DROP TRIGGER IF EXISTS trg_topic_duration_update ON private.speeches;"""

    trigger_update = """
    CREATE TRIGGER trg_topic_duration_update
    AFTER INSERT ON private.speeches
    FOR EACH ROW
    EXECUTE FUNCTION private.trgfn_topic_duration_update();"""

    trigger_delete_drop = """
    DROP TRIGGER IF EXISTS trg_topic_duration_delete ON private.speeches;"""

    trigger_delete = """
    CREATE TRIGGER trg_topic_duration_delete
    AFTER INSERT ON private.speeches
    FOR EACH ROW
    EXECUTE FUNCTION private.trgfn_topic_duration_delete();"""


    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute(create_private_schema)
            cur.execute(create_speakers_table)
            cur.execute(create_files_table)
            cur.execute(create_topics_table)
            cur.execute(create_table_speeches)
            cur.execute(default_speaker)
            cur.execute(function_trigger_insert)
            cur.execute(function_trigger_update)
            cur.execute(function_trigger_delete)
            cur.execute(trigger_insert_drop)
            cur.execute(trigger_insert)
            cur.execute(trigger_update_drop)
            cur.execute(trigger_update)
            cur.execute(trigger_delete_drop)
            cur.execute(trigger_delete)
        conn.commit()

    print("Database and tables created successfully.")

def views_db(db_url):
    
    create_schemas = """
    CREATE SCHEMA IF NOT EXISTS dashboard;
    CREATE SCHEMA IF NOT EXISTS dashboard_internal;
    """

    create_roles = """
    DO $$
    BEGIN
        IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'dashboard_owner') THEN
            CREATE ROLE dashboard_owner NOINHERIT;
        END IF;
        IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'dashboard_reader') THEN
            CREATE ROLE dashboard_reader NOINHERIT;
        END IF;
    END;
    $$;
    """

    ownership_schemas = """
    ALTER SCHEMA dashboard OWNER TO dashboard_owner;
    ALTER SCHEMA dashboard_internal OWNER TO dashboard_owner;
    """

    lockdown_schemas = """
    REVOKE ALL ON SCHEMA dashboard_internal FROM PUBLIC, anon, authenticated;
    REVOKE ALL ON SCHEMA private FROM PUBLIC, anon, authenticated;
    REVOKE ALL ON SCHEMA dashboard FROM PUBLIC, anon, authenticated;
    """

    grant_select_private = """
    GRANT SELECT ON private.speeches TO dashboard_owner;
    GRANT SELECT ON private.topics TO dashboard_owner;
    GRANT SELECT ON private.files TO dashboard_owner;
    """

    # security definer function in dashboard_internal (are executed with owners privileges)
    sd_functions = """
    -- topics read function
    CREATE OR REPLACE FUNCTION dashboard_internal._fn_topics_read()
    RETURNS TABLE (
        topic_id INTEGER,
        topic_keywords TEXT,
        topic_label TEXT,
        topic_duration INTERVAL,
        topic_duration_bt INTERVAL,
        topic_duration_ts INTERVAL
    )
    LANGUAGE sql
    SECURITY DEFINER SET search_path = pg_catalog, private
    STABLE
    AS $$
        SELECT * 
        FROM private.topics;
    $$;
    REVOKE ALL ON FUNCTION dashboard_internal._fn_topics_read() FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard_internal._fn_topics_read() TO dashboard_reader;

    -- function for windowed metrics
    CREATE OR REPLACE FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(
        p_year         int,
        p_window_weeks int
    )
    RETURNS TABLE (
        window_start date,
        window_end   date,

        topic_id integer,
        topic_label text,
        topic_keywords text,

        topic_duration interval,
        topic_duration_bt interval,
        topic_duration_ts interval,

        bt_normalized_perc numeric,
        ts_normalized_perc numeric,

        mismatch_ppoints numeric,
        mismatch_log_ratio numeric
    )
    LANGUAGE sql
    SECURITY DEFINER
    SET search_path = pg_catalog, private
    STABLE
    AS $$
    WITH params AS (
    SELECT
        make_date(p_year, 1, 1)::date         AS start_date,
        make_date(p_year + 1, 1, 1)::date     AS end_date,       -- exclusive end
        (p_window_weeks || ' weeks')::interval AS step
    ),
    windows AS (
    SELECT
        gs::date AS window_start,
        LEAST((gs + p.step)::date, p.end_date) AS window_end
    FROM params p
    CROSS JOIN generate_series(p.start_date, p.end_date - p.step, p.step) AS gs
    ),
    speech_rows AS (
    SELECT
        w.window_start,
        w.window_end,
        s.topic AS topic_id,
        f.source,
        s.speech_duration
    FROM windows w
    JOIN private.files f
        ON f.file_date >= w.window_start
    AND f.file_date <  w.window_end
    JOIN private.speeches s
        ON s.file = f.file_id
    WHERE s.topic IS NOT NULL
    ),
    agg AS (
    SELECT
        window_start,
        window_end,
        topic_id,
        SUM(speech_duration) AS topic_duration,
        SUM(speech_duration) FILTER (WHERE source = 'bundestag') AS topic_duration_bt,
        SUM(speech_duration) FILTER (WHERE source = 'talkshow')  AS topic_duration_ts
    FROM speech_rows
    GROUP BY 1,2,3
    ),
    base AS (
    SELECT
        a.window_start,
        a.window_end,
        t.topic_id,
        t.topic_label,
        t.topic_keywords,
        a.topic_duration,
        a.topic_duration_bt,
        a.topic_duration_ts,
        EXTRACT(EPOCH FROM a.topic_duration_bt)::numeric AS bt_seconds,
        EXTRACT(EPOCH FROM a.topic_duration_ts)::numeric AS ts_seconds
    FROM agg a
    JOIN private.topics t ON t.topic_id = a.topic_id
    ),
    norm AS (
    SELECT
        *,
        bt_seconds / NULLIF(SUM(bt_seconds) OVER (PARTITION BY window_start), 0) AS bt_normalized,
        ts_seconds / NULLIF(SUM(ts_seconds) OVER (PARTITION BY window_start), 0) AS ts_normalized
    FROM base
    )
    SELECT
    window_start,
    window_end,

    topic_id,
    topic_label,
    topic_keywords,

    topic_duration,
    topic_duration_bt,
    topic_duration_ts,

    (bt_normalized * 100) AS bt_normalized_perc,
    (ts_normalized * 100) AS ts_normalized_perc,
    (bt_normalized - ts_normalized)*100 AS mismatch_ppoints,
    log((bt_normalized+0.0000001)/(ts_normalized+0.0000001)) AS mismatch_log_ratio
    FROM norm
    ORDER BY window_start, topic_id;
    $$;

    REVOKE ALL ON FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(int,int)
    FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(int,int)
    TO dashboard_reader;

    -- public wrapper function for windowed metrics
    CREATE OR REPLACE FUNCTION dashboard.topics_metrics_all_xweek_windows(
    p_year int,
    p_window_weeks int
    )
    RETURNS TABLE (
    window_start date,
    window_end   date,

    topic_id integer,
    topic_label text,
    topic_keywords text,

    topic_duration interval,
    topic_duration_bt interval,
    topic_duration_ts interval,

    bt_normalized_perc numeric,
    ts_normalized_perc numeric,

    mismatch_ppoints numeric,
    mismatch_log_ratio numeric
    )
    LANGUAGE sql
    SECURITY DEFINER
    SET search_path = pg_catalog  
    STABLE
    AS $$
    SELECT *
    FROM dashboard_internal._fn_topics_metrics_all_xweek_windows(p_year, p_window_weeks);
    $$;

    REVOKE ALL ON FUNCTION dashboard.topics_metrics_all_xweek_windows(int,int)
    FROM PUBLIC, anon, authenticated;
    GRANT EXECUTE ON FUNCTION dashboard.topics_metrics_all_xweek_windows(int,int)
    TO dashboard_reader;
    """

    ownership_functions = """
    ALTER FUNCTION dashboard_internal._fn_topics_read() OWNER TO dashboard_owner;
    ALTER FUNCTION dashboard_internal._fn_topics_metrics_all_xweek_windows(int,int) OWNER TO dashboard_owner;
    ALTER FUNCTION dashboard.topics_metrics_all_xweek_windows(int,int) OWNER TO dashboard_owner;
    """

    create_views = """
    -- topics view
    CREATE OR REPLACE VIEW dashboard.topics_view AS
    WITH base AS (
    SELECT
        topic_id,
        topic_label,
        topic_keywords,
        topic_duration,
        topic_duration_bt,
        topic_duration_ts,

        -- convert intervals to seconds (numeric)
        EXTRACT(EPOCH FROM topic_duration_bt)::numeric AS bt_seconds,
        EXTRACT(EPOCH FROM topic_duration_ts)::numeric AS ts_seconds
    FROM dashboard_internal._fn_topics_read()
    ),
    norm AS (
    SELECT
        *,
        bt_seconds / NULLIF(SUM(bt_seconds) OVER (), 0) AS bt_normalized,
        ts_seconds / NULLIF(SUM(ts_seconds) OVER (), 0) AS ts_normalized
    FROM base
    )
    SELECT
    topic_id,
    topic_label,
    topic_keywords,
    topic_duration,
    topic_duration_bt,
    topic_duration_ts,
    (bt_normalized*100) AS bt_normalized_perc,
    (ts_normalized*100) AS ts_normalized_perc,
    (bt_normalized / NULLIF(bt_normalized + ts_normalized, 0))*100 AS bt_share,
    (ts_normalized / NULLIF(bt_normalized + ts_normalized, 0))*100 AS ts_share,
    (bt_normalized - ts_normalized)*100 AS mismatch_ppoints,
    log((bt_normalized+0.0000001)/(ts_normalized+0.0000001)) AS mismatch_log_ratio
    FROM norm;

    -- 4-week windowed metrics view
    CREATE OR REPLACE VIEW dashboard.topics_view_2025_4w AS
    SELECT *
    FROM dashboard_internal._fn_topics_metrics_all_xweek_windows(2025, 4);
    """

    ownership_views = """
    ALTER VIEW dashboard.topics_view OWNER TO dashboard_owner;
    ALTER VIEW dashboard.topics_view_2025_4w OWNER TO dashboard_owner;
    """

    minimal_rights = """
    GRANT USAGE ON SCHEMA dashboard TO dashboard_reader;
    REVOKE ALL ON dashboard.topics_view FROM PUBLIC, anon, authenticated;
    GRANT SELECT ON dashboard.topics_view TO dashboard_reader;
    REVOKE ALL ON dashboard.topics_view_2025_4w FROM PUBLIC, anon, authenticated;
    GRANT SELECT ON dashboard.topics_view_2025_4w TO dashboard_reader;
    """

    grant_anon_role = """
    GRANT dashboard_reader TO anon;"""

    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute(create_schemas)
            cur.execute(create_roles)
            cur.execute(ownership_schemas)
            cur.execute(lockdown_schemas)
            cur.execute(grant_select_private)
            cur.execute(sd_functions)
            cur.execute(ownership_functions)
            cur.execute(create_views)
            cur.execute(ownership_views)
            cur.execute(minimal_rights)
            cur.execute(grant_anon_role)
            
        conn.commit()

def comment_db(db_url):
    views = """
    COMMENT ON VIEW dashboard.topics_view IS 
    'This view contains general information on all the topics identified in Bundestag and Talkshow speeches.';
    COMMENT ON VIEW dashboard.topics_view_2025_4w IS 
    'This view contains the same measurements as topics_view, but for a 4-week window. That means, one row in this view represents one specific topic that was talked about in a specific 4-week window.';
    """

    functions = """
    COMMENT ON FUNCTION dashboard.topics_metrics_all_xweek_windows (int, int) IS 
    'This function returns the topic measurements for a user defined timewindow and year.
    
    Paraneters:
    - p_year: Calender year to analyze (e.g. 2025)
    - p_window_weeks: window size in weeks (e.g. 4)
    
    The output of the function is a table with the same columns as in topics_view_2025_4w';
    """

    columns = """
    -- topics_view
    COMMENT ON COLUMN dashboard.topics_view.topic_id IS
    'Unique topic identifier';
    COMMENT ON COLUMN dashboard.topics_view.topic_label IS
    'Labels of topics';
    COMMENT ON COLUMN dashboard.topics_view.topic_keywords IS
    'Descriptive keywords of topic';
    COMMENT ON COLUMN dashboard.topics_view.topic_duration IS
    'Overall observed speech time spent on topic without differentiating between Bundestag and Talkshows';
    COMMENT ON COLUMN dashboard.topics_view.topic_duration_bt IS
    'Observed speech time spent on topic in Bundestag';
    COMMENT ON COLUMN dashboard.topics_view.topic_duration_ts IS
    'Observed speech time spent on topic in Talkshows';
    COMMENT ON COLUMN dashboard.topics_view.bt_normalized_perc IS
    'Normalized topic speech time in Bundestag in percentages; constructed by dividing the observed time spent on specific topic in Bundestag by the total observed speech time in Bundestag.';
    COMMENT ON COLUMN dashboard.topics_view.ts_normalized_perc IS
    'Normalized topic speech time in Talkshows in percentages; constructed by dividing the observed time spent on specific topic in Talkshows by the total observed speech time in Talkshows.';
    COMMENT ON COLUMN dashboard.topics_view.bt_share IS
    'Normalized share of salience in Bundestag in percentages; constructed by dividing the normalized topic speech time of Bundestag with the total normalized topic speech time.';
    COMMENT ON COLUMN dashboard.topics_view.ts_share IS
    'Normalized share of salience in Talkshows in percentages; constructed by dividing the normalized topic speech time of Talkshows with the total normalized topic speech time.';
    COMMENT ON COLUMN dashboard.topics_view.mismatch_ppoints IS
    'Difference of normalized topic speech time in Bundestag and Talkshows in percentage points (ranges from -100 to 100); positive means higher salience of topic in Bundestag, negative means higher salience in Talkshows, 0 indicates equal salience.';
    COMMENT ON COLUMN dashboard.topics_view.mismatch_log_ratio IS
    'Log of ratio of normalized topic speech times in Bundestag and Talkshows; positive means higher salience of topic in Bundestag, negative means higher salience in Talkshows, 0 indicates equal salience.';
    
    -- topics_view_2025_4w
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.window_start IS
    'Start date of window (inclusive)';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.window_end IS
    'End date of window (exclusive)';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.topic_id IS
    'Unique topic identifier';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.topic_label IS
    'Labels of topics';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.topic_keywords IS
    'Descriptive keywords of topic';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.topic_duration IS
    'Overall observed speech time spent on topic without differentiating between Bundestag and Talkshows';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.topic_duration_bt IS
    'Observed speech time spent on topic in Bundestag';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.topic_duration_ts IS
    'Observed speech time spent on topic in Talkshows';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.bt_normalized_perc IS
    'Normalized topic speech time in Bundestag in percentages; constructed by dividing the observed time spent on specific topic in Bundestag by the total observed speech time in Bundestag.';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.ts_normalized_perc IS
    'Normalized topic speech time in Talkshows in percentages; constructed by dividing the observed time spent on specific topic in Talkshows by the total observed speech time in Talkshows.';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.mismatch_ppoints IS
    'Difference of normalized topic speech time in Bundestag and Talkshows in percentage points (ranges from -100 to 100); positive means higher salience of topic in Bundestag, negative means higher salience in Talkshows, 0 indicates equal salience.';
    COMMENT ON COLUMN dashboard.topics_view_2025_4w.mismatch_log_ratio IS
    'Log of ratio of normalized topic speech times in Bundestag and Talkshows; positive means higher salience of topic in Bundestag, negative means higher salience in Talkshows, 0 indicates equal salience.';
    """

    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            cur.execute(views)
            cur.execute(functions)
            cur.execute(columns)
            
        conn.commit()


def fill_db(db_url, input_path):

    def norm_text(x):
        if x is None or pd.isna(x):
            return "Unknown"
        x = unicodedata.normalize("NFKC", str(x))
        x = x.replace("\u00A0", " ").strip()
        return x if x else "Unknown"

    def make_speech_key(speech_text, seconds, file_id, speaker_id, topic_id):
        raw = f"{speech_text}|{seconds}|{file_id}|{speaker_id}|{topic_id}"
        return hashlib.sha256(raw.encode("utf-8")).hexdigest()

    upsert_speaker = """
    INSERT INTO private.speakers (speaker_name, speaker_party)
    VALUES (%s, %s)
    ON CONFLICT (speaker_name, speaker_party)
    DO UPDATE SET 
        speaker_name = EXCLUDED.speaker_name
    RETURNING speaker_id;"""

    upsert_file = """
    INSERT INTO private.files (file_name, file_date, file_year, source)
    VALUES (%s, %s, %s, %s)
    ON CONFLICT (file_name)
    DO UPDATE SET 
        file_name = EXCLUDED.file_name
    RETURNING file_id;"""

    upsert_topic = """
    INSERT INTO private.topics (topic_id, topic_keywords, topic_label)
    VALUES (%s, %s, %s)
    ON CONFLICT (topic_id)
    DO NOTHING;"""

    upsert_speech = """
    INSERT INTO private.speeches (speech_key, speech_text, speech_duration, file, speaker, topic)
    VALUES (%s, %s, make_interval(secs => %s), %s, %s, %s)
    ON CONFLICT (speech_key)
    DO NOTHING;"""

    speaker_cache = {}
    file_cache = {}
    topic_cache = set()

    with psycopg2.connect(db_url) as conn:
        with conn.cursor() as cur:
            with open(input_path, encoding="utf-8") as tr:
                reader = csv.DictReader(tr)

                for i, row in enumerate(reader, start=1):
                    # getting data
                    speaker_name = norm_text(row["protokoll_name"])
                    speaker_party = norm_text(row["protokoll_party"])
                    file_name = norm_text(row["filename"])
                    file_date = norm_text(row["date"])
                    file_year = int(file_date[:4])
                    source = row["source"]
                    if source == "bundestag":
                        seconds = float(row["transcript_end"]) - float(row["transcript_start"])
                    elif source == "talkshow":
                        seconds = float(row["end"]) - float(row["start"])
                    else:
                        print(f"Unknown source: {source}")
                        continue
                    topic_id = int(row["topic"])
                    topic_keywords = row["Representation"]
                    topic_label = "Unknown"
                    speech_text = norm_text(row["text"])

                    # upserting data
                    # speaker
                    skey = (speaker_name, speaker_party)
                    speaker_id = speaker_cache.get(skey)
                    if speaker_id is None:
                        cur.execute(upsert_speaker, (speaker_name, speaker_party))
                        speaker_id = cur.fetchone()[0]
                        speaker_cache[skey] = speaker_id
                    # file
                    file_id = file_cache.get(file_name)
                    if file_id is None:
                        cur.execute(upsert_file, (file_name, file_date, file_year, source))
                        file_id = cur.fetchone()[0]
                        file_cache[file_name] = file_id
                    # topic
                    if topic_id not in topic_cache:
                        cur.execute(upsert_topic, (topic_id, topic_keywords, topic_label))
                        topic_cache.add(topic_id)
                    # speech
                    speech_key = make_speech_key(speech_text, seconds, file_id, speaker_id, topic_id)
                    cur.execute(upsert_speech, (speech_key, speech_text, seconds, file_id, speaker_id, topic_id))
            
                    # committing
                    if i % 5000 == 0:
                        conn.commit()
                        print(f"Inserted/updated {i} rows...")
            conn.commit()

    print("Database population completed.")
